# 0-markov_chain.py

This script implements a basic Markov Chain. A Markov Chain is a stochastic model that describes a sequence of possible events where the probability of each event depends only on the state attained in the previous event.

## Features

- Define states and transition probabilities
- Generate sequences of states
- Calculate steady-state probabilities