{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fb7bc95",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#!/usr/bin/env python3\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Imports and setup\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Imports and setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Initialize W&B project\n",
    "wandb.init(project=\"mnist_dcgan\", config={\n",
    "    \"dataset\": \"MNIST\",\n",
    "    \"framework\": \"PyTorch\",\n",
    "    \"model\": \"DCGAN\"\n",
    "})\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define preprocessing for MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Download MNIST training dataset  \n",
    "dataset = datasets.MNIST(root='./data',\n",
    "                         train=True,\n",
    "                         download=True,\n",
    "                         transform=transform)\n",
    "\n",
    "# Create DataLoader with batch size and shuffle\n",
    "batch_size = 128\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)  \n",
    "\n",
    "# Get one batch to check shapes  \n",
    "real_batch = next(iter(dataloader))\n",
    "images, labels = real_batch\n",
    "\n",
    "# Print shape of batch to verify \n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "# Undo normalization for visual\n",
    "images = images * 0.5 + 0.5\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(images[i].squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c665eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "lr = 0.0002\n",
    "img_ch = 1\n",
    "img_size = 28\n",
    "Beta1 = 0.5\n",
    "batch_size = 128\n",
    "epochs = 50\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generator Network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_ch):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Starting size will be 7x7 after first layer\n",
    "        self.init_size = 7\n",
    "\n",
    "        # Linear layer to expand latent vector\n",
    "        self.fc = nn.Linear(latent_dim, 128 * self.init_size ** 2)\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential(\n",
    "          nn.BatchNorm2d(128),\n",
    "\n",
    "          # Upsample to 14x14\n",
    "          nn.Upsample(scale_factor=2),\n",
    "          nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "          nn.BatchNorm2d(128),\n",
    "          nn.LeakyReLU(inplace=True),\n",
    "          \n",
    "          # Upsample to 28x28\n",
    "          nn.Upsample(scale_factor=2),\n",
    "          nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "          nn.BatchNorm2d(64),\n",
    "          nn.LeakyReLU(inplace=True),\n",
    "          \n",
    "          # Output layer\n",
    "          nn.Conv2d(64, img_ch, 3, stride=1, padding=1),\n",
    "          nn.Tanh()\n",
    "          # Output range [-1, 1]\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        # z shape: (batch_size, latent_dim)\n",
    "        out = self.fc(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f214432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator Network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_ch):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # Input: 1x28x28\n",
    "            nn.Conv2d(img_ch, 64, 4, stride=2, padding= 1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            # 14x14\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 7x7\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # 3x3\n",
    "            nn.Conv2d(256, 512, 3, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "            )\n",
    "        self.adv_layer = nn.Sequential(\n",
    "        # Flatten and output single value\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 2 * 2, 1),  # Corrected input size for linear layer\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        validity = self.adv_layer(out)\n",
    "        return validity\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f9f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight initialization (important for GANs)\n",
    "def weights_init(m):\n",
    "  classname = m.__class__.__name__\n",
    "  if classname.find('Conv') != -1:\n",
    "    nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "  elif classname.find('BatchNorm') != -1:\n",
    "    nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "    nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "# Training function\n",
    "def train_dcgan(dataloader, num_epochs, batch_size):\n",
    "\n",
    "  # Initialize models\n",
    "  generator = Generator(latent_dim, img_ch).to(device)\n",
    "  discriminator = Discriminator(img_ch).to(device)\n",
    "\n",
    "  # Apply weight initialization\n",
    "  generator.apply(weights_init)\n",
    "  discriminator.apply(weights_init)\n",
    "  # Loss function\n",
    "  bce_loss = nn.BCELoss()\n",
    "  # Optimizers\n",
    "  optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(Beta1, 0.999))\n",
    "  optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(Beta1, 0.999))\n",
    "  # update WandB\n",
    "  wandb.config.update({\n",
    "      \"latent_dim\": latent_dim,\n",
    "      \"batch_size\": batch_size,\n",
    "      \"learning_rate\": lr,\n",
    "      \"num_epochs\": num_epochs,\n",
    "      \"architecture\": \"Baseline DCGAN\"\n",
    "      })\n",
    "  # wandb.watch(generator)\n",
    "  # wandb.watch(discriminator)\n",
    "\n",
    "  # Fixed noise for visualization\n",
    "  fixed_noise = torch.randn(64, latent_dim).to(device)\n",
    "  print(f\"Generator parameters: {sum(p.numel() for p in generator.parameters()):,}\")\n",
    "  print(f\"Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}\")\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "    for i, (real_imgs,_) in enumerate(dataloader):\n",
    "      # batch_size = real_imgs.size(0) # Removed this line\n",
    "      real_imgs = real_imgs.to(device)\n",
    "\n",
    "      # Labels for real and fake images\n",
    "      real_labels = torch.ones(batch_size, 1).to(device)\n",
    "      fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "      # ---------------------\n",
    "      #  Train Discriminator\n",
    "      # ---------------------\n",
    "\n",
    "      optimizer_D.zero_grad()\n",
    "\n",
    "      # Loss on real images\n",
    "      real_out = discriminator(real_imgs)\n",
    "      d_real_loss = bce_loss(real_out, real_labels)\n",
    "\n",
    "      # Generate fake images\n",
    "      z = torch.randn(batch_size, latent_dim).to(device)\n",
    "      fake_imgs = generator(z)\n",
    "\n",
    "      # Loss on fake images\n",
    "      fake_out = discriminator(fake_imgs.detach())\n",
    "      d_fake_loss = bce_loss(fake_out, fake_labels)\n",
    "\n",
    "      # Total discriminator loss\n",
    "      d_loss = d_real_loss + d_fake_loss\n",
    "      d_loss.backward()\n",
    "      optimizer_D.step()\n",
    "\n",
    "    # -----------------\n",
    "    #  Train Generator\n",
    "    # -----------------\n",
    "    optimizer_G.zero_grad()\n",
    "\n",
    "    # Generate fake images\n",
    "    z = torch.randn(batch_size, latent_dim).to(device)\n",
    "    fake_imgs = generator(z)\n",
    "\n",
    "    # Loss on fake images\n",
    "    fake_out = discriminator(fake_imgs)\n",
    "    g_loss = bce_loss(fake_out, real_labels)\n",
    "\n",
    "    # Generator tries to fool discriminator\n",
    "    g_loss.backward()\n",
    "    optimizer_G.step()\n",
    "\n",
    "    # ---------------------\n",
    "    #  Log metrics\n",
    "    # ---------------------\n",
    "\n",
    "    if i % 100 == 0:\n",
    "      print(f\"[Epoch {epoch}/{num_epochs}],\"\n",
    "      f\"[Batch {i}/{len(dataloader)}],\"\n",
    "      f\"D_loss: {d_loss.item():.4f},\"\n",
    "      f\"G_loss: {g_loss.item():.4f}\")\n",
    "\n",
    "    # Log to WandB at end of epoch\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch,\n",
    "        \"d_loss\": d_loss.item(),\n",
    "        \"g_loss\": g_loss.item(),\n",
    "        \"d_real_acc\": (real_out >= 0.5, real_labels).float().mean().item(),\n",
    "        \"d_fake_acc\": (fake_out < 0.5, fake_labels).float().mean().item()\n",
    "        })\n",
    "\n",
    "    # Generate and log images every 5 epochs\n",
    "    if epoch % 5 == 0:\n",
    "      with torch.no_grad():\n",
    "        fake_imgs = generator(fixed_noise).detach().cpu()\n",
    "\n",
    "        # Denormalize images from [-1, 1] to [0, 1]\n",
    "        fake_imgs = (fake_imgs + 1) / 2\n",
    "        # Create grid of images\n",
    "        grid = torchvision.utils.make_grid(fake_imgs,\n",
    "                                           nrow=8,\n",
    "                                           padding=2,\n",
    "                                           normalize=False)\n",
    "        # Log to WandB\n",
    "        wandb.log({\"generated_images\": wandb.Image(grid)})\n",
    "        save_image(fake_imgs[:64],f'generated_epoch_{epoch}.png', nrow=8, padding=2, normalize=False)\n",
    "\n",
    "# Save final models\n",
    "  torch.save(generator.state_dict(), \"generator.pth\")\n",
    "  torch.save(discriminator.state_dict(), \"discriminator.pth\")\n",
    "  wandb.save(\"generator.pth\")\n",
    "  wandb.save(\"discriminator.pth\")\n",
    "\n",
    "  return generator, discriminator\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a5fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "# if __name__ == \"__main__\":\n",
    "  # Train the DCGAN\n",
    "generator, discriminator = train_dcgan(dataloader, epochs, batch_size)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d2222d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.9.0-cp310-cp310-win_amd64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.24.0-cp310-cp310-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.9.0-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\phoen\\anaconda3\\envs\\ml\\lib\\site-packages (from torch) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\phoen\\anaconda3\\envs\\ml\\lib\\site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\phoen\\anaconda3\\envs\\ml\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\phoen\\anaconda3\\envs\\ml\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\phoen\\anaconda3\\envs\\ml\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.9.0-cp310-cp310-win_amd64.whl (109.3 MB)\n",
      "   ---------------------------------------- 0.0/109.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/109.3 MB 6.7 MB/s eta 0:00:17\n",
      "    --------------------------------------- 2.1/109.3 MB 4.9 MB/s eta 0:00:22\n",
      "   - -------------------------------------- 2.9/109.3 MB 4.7 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 4.2/109.3 MB 5.1 MB/s eta 0:00:21\n",
      "   -- ------------------------------------- 5.5/109.3 MB 5.4 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 6.8/109.3 MB 5.6 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 8.1/109.3 MB 5.7 MB/s eta 0:00:18\n",
      "   --- ------------------------------------ 9.4/109.3 MB 5.8 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 11.0/109.3 MB 5.9 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 12.3/109.3 MB 5.9 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 13.6/109.3 MB 6.0 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 14.7/109.3 MB 6.0 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 15.2/109.3 MB 5.7 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 16.0/109.3 MB 5.6 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 17.0/109.3 MB 5.5 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 18.1/109.3 MB 5.4 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 19.1/109.3 MB 5.4 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 20.4/109.3 MB 5.5 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 21.8/109.3 MB 5.5 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 22.5/109.3 MB 5.4 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 23.6/109.3 MB 5.4 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 24.1/109.3 MB 5.3 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 25.2/109.3 MB 5.3 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 26.0/109.3 MB 5.2 MB/s eta 0:00:16\n",
      "   --------- ------------------------------ 27.0/109.3 MB 5.2 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 27.8/109.3 MB 5.2 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 29.1/109.3 MB 5.2 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 30.4/109.3 MB 5.2 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 31.7/109.3 MB 5.3 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 32.8/109.3 MB 5.3 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 34.1/109.3 MB 5.3 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 35.1/109.3 MB 5.3 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 36.4/109.3 MB 5.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 37.5/109.3 MB 5.3 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 38.8/109.3 MB 5.3 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 39.6/109.3 MB 5.3 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 39.8/109.3 MB 5.2 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 40.1/109.3 MB 5.1 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 40.4/109.3 MB 5.0 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 40.9/109.3 MB 4.9 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 41.2/109.3 MB 4.9 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 41.4/109.3 MB 4.8 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 41.7/109.3 MB 4.7 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 41.9/109.3 MB 4.6 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 42.2/109.3 MB 4.5 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 42.2/109.3 MB 4.5 MB/s eta 0:00:15\n",
      "   --------------- ------------------------ 42.5/109.3 MB 4.4 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 42.5/109.3 MB 4.4 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 42.7/109.3 MB 4.2 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 43.0/109.3 MB 4.1 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 43.3/109.3 MB 4.1 MB/s eta 0:00:17\n",
      "   --------------- ------------------------ 43.5/109.3 MB 4.1 MB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 43.8/109.3 MB 4.0 MB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 44.3/109.3 MB 3.9 MB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 44.6/109.3 MB 3.9 MB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 44.8/109.3 MB 3.9 MB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 45.1/109.3 MB 3.8 MB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 46.1/109.3 MB 3.8 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 47.4/109.3 MB 3.9 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 49.0/109.3 MB 3.9 MB/s eta 0:00:16\n",
      "   ------------------ --------------------- 50.1/109.3 MB 4.0 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 51.4/109.3 MB 4.0 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 52.2/109.3 MB 4.0 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 53.2/109.3 MB 4.0 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 54.0/109.3 MB 4.0 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 55.3/109.3 MB 4.0 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 56.4/109.3 MB 4.1 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 56.9/109.3 MB 4.0 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 57.9/109.3 MB 4.0 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 59.0/109.3 MB 4.1 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 59.8/109.3 MB 4.1 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 61.1/109.3 MB 4.1 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 62.1/109.3 MB 4.1 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 63.4/109.3 MB 4.1 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 64.5/109.3 MB 4.2 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 65.8/109.3 MB 4.2 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 67.1/109.3 MB 4.2 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 68.4/109.3 MB 4.2 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 69.7/109.3 MB 4.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 71.3/109.3 MB 4.3 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 73.1/109.3 MB 4.4 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 74.4/109.3 MB 4.4 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 75.5/109.3 MB 4.4 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 76.8/109.3 MB 4.4 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 78.1/109.3 MB 4.4 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 79.4/109.3 MB 4.5 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 80.7/109.3 MB 4.5 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 81.8/109.3 MB 4.5 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 82.8/109.3 MB 4.5 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 83.6/109.3 MB 4.5 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 84.4/109.3 MB 4.5 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 85.5/109.3 MB 4.5 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 86.5/109.3 MB 4.5 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 87.0/109.3 MB 4.5 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 87.6/109.3 MB 4.5 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 88.3/109.3 MB 4.5 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 89.7/109.3 MB 4.5 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 90.7/109.3 MB 4.5 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 91.8/109.3 MB 4.5 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 93.1/109.3 MB 4.5 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 93.8/109.3 MB 4.5 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 94.9/109.3 MB 4.5 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 95.9/109.3 MB 4.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 97.0/109.3 MB 4.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 98.3/109.3 MB 4.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 99.4/109.3 MB 4.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 100.7/109.3 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 102.0/109.3 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 103.3/109.3 MB 4.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 104.6/109.3 MB 4.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 105.9/109.3 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  107.0/109.3 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  108.0/109.3 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.1/109.3 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.1/109.3 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.1/109.3 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 109.3/109.3 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.24.0-cp310-cp310-win_amd64.whl (3.7 MB)\n",
      "   ---------------------------------------- 0.0/3.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 1.0/3.7 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.1/3.7 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.1/3.7 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.7/3.7 MB 5.3 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.9.0-cp310-cp310-win_amd64.whl (663 kB)\n",
      "   ---------------------------------------- 0.0/663.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 663.9/663.9 kB 4.3 MB/s eta 0:00:00\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 1.0/1.7 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 5.5 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.8/6.3 MB 3.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.6/6.3 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.6/6.3 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.9/6.3 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.0/6.3 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.3 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 6.0 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, filelock, torch, torchvision, torchaudio\n",
      "Successfully installed filelock-3.20.0 fsspec-2025.9.0 mpmath-1.3.0 networkx-3.4.2 sympy-1.14.0 torch-2.9.0 torchaudio-2.9.0 torchvision-0.24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install torch torchvision torchaudio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
